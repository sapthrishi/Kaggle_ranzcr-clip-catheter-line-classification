{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/ffn-v2/ffn.pth","execution_count":48,"outputs":[{"output_type":"stream","text":"../input/ffn-v2/ffn.pth\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/resnet200d-320-640-fold0-colab-enx7/resnet200d_320_640_fold0_colab_eNx7.pth","execution_count":49,"outputs":[{"output_type":"stream","text":"../input/resnet200d-320-640-fold0-colab-enx7/resnet200d_320_640_fold0_colab_eNx7.pth\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/resnet200d-320-640-fold0-colab-enx2/resnet200d_320_fold0_colab_eNx2.pth","execution_count":50,"outputs":[{"output_type":"stream","text":"../input/resnet200d-320-640-fold0-colab-enx2/resnet200d_320_fold0_colab_eNx2.pth\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/resnet200d-320-fold0-enx7/resnet200d_320_fold0_eNx7.pth","execution_count":51,"outputs":[{"output_type":"stream","text":"../input/resnet200d-320-fold0-enx7/resnet200d_320_fold0_eNx7.pth\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/resnet200d320fold0-end/resnet200d_320_fold0_end.pth","execution_count":52,"outputs":[{"output_type":"stream","text":"../input/resnet200d320fold0-end/resnet200d_320_fold0_end.pth\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/pytorch-images-seresnet')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport os\nimport gc\nimport time\nimport math\nimport random\nimport datetime\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom   torch.nn import CrossEntropyLoss, MSELoss\nfrom   torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\nfrom   torch.nn import Parameter\nfrom   torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom   transformers import TrainingArguments, Trainer, AdamW, get_linear_schedule_with_warmup\n\nfrom   fastai.losses import LabelSmoothingCrossEntropy\n\n# from   warmup_scheduler import GradualWarmupScheduler\nfrom   sklearn import preprocessing\nfrom   sklearn.metrics import accuracy_score\nfrom   sklearn.model_selection import StratifiedKFold, GroupKFold\nfrom   sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef, roc_auc_score\nfrom   sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n\nimport timm\nimport albumentations as A\nfrom   albumentations.pytorch import ToTensorV2\nfrom   albumentations.core.transforms_interface import DualTransform\nfrom   albumentations.augmentations import functional as AF\nimport cv2\n\nfrom   tqdm import tqdm\nfrom   pprint import pprint\nfrom   functools import partial\nimport matplotlib.pyplot as plt\nfrom   numba import cuda\nimport warnings\nwarnings.filterwarnings (\"ignore\")","execution_count":53,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"class CFG:    \n    IMAGE_SIZE = 640\n    TEST_PATH  = '../input/ranzcr-clip-catheter-line-classification/test'\n    device       = torch.device ('cuda' if torch.cuda.is_available () else 'cpu')\n    num_workers  = 4\n    model_name   = 'resnet200d_320' # ['deit_base_patch16_224', 'vit_base_patch16_384', 'resnext50_32x4d', 'tf_efficientnet_b7_ns']\n    size         = 640  # [64, 128, 224, 384, 512, 640, 720]\n    train        = True\n    freeze       = True     # this is updated during training   \n    freeze_epo   = 0.5       # float: these many epochs are with frozen model at the beginning\n    epochs       = 1 \n    epochsNx     = 40\n    lr           = 5e-4\n    criterion    = 'BCEWithLogitsLoss'    # ['CrossEntropyLoss', 'BCEWithLogitsLoss', 'SmoothBCEwithLogits']\n    batch_size   = 95 #[10, 32, 64]\n    weight_decay = 1e-6\n    max_grad_norm= 1000.0\n    seed         = 42\n    target_size  = -1    # init below\n    n_fold       = 50\n    train_fold   = [0] #, 1, 2, 3, 4]\n    print_every  = 100\n    img_ext      = '.jpg'\n    img_col      = \"StudyInstanceUID\"\n    label_cols   = [\n                    'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n                    'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n                    'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n                    'Swan Ganz Catheter Present'\n    ]\n    train_path   = '../input/ranzcr-clip-catheter-line-classification/train'\n    train_csv    = '../input/ranzcr-clip-catheter-line-classification/train.csv'\n    test_path    = '../input/ranzcr-clip-catheter-line-classification/test'\n    test_csv     = '../input/ranzcr-clip-catheter-line-classification/sample_submission.csv'    \n    \n    MODEL_PATHS  = [\n        '../input/resnet200d-320-640-fold0-colab-enx7/resnet200d_320_640_fold0_colab_eNx7.pth',\n        '../input/resnet200d-320-640-fold0-colab-enx2/resnet200d_320_fold0_colab_eNx2.pth',\n        '../input/resnet200d-320-fold0-enx7/resnet200d_320_fold0_eNx7.pth',\n        '../input/resnet200d320fold0-end/resnet200d_320_fold0_end.pth',\n    ]\n    MODELS       = []\n    MODEL_LOGITS = []\n    BATCH_LABELS = []\n    ffn_path     = '../input/ffn-v2/ffn.pth'","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything (seed):\n    \n    random.seed (seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed (seed)\n    torch.manual_seed (seed)\n    torch.cuda.manual_seed (seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    return\n\nseed_everything (CFG.seed)","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv (CFG.test_csv)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_transforms ():\n        return A.Compose ([\n            A.Resize (CFG.size, CFG.size),\n            A.Normalize (),\n            ToTensorV2 (),\n        ])","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImgDataset (Dataset):\n    \n    def __init__(self, df, img_file_colname=CFG.img_col, label_cols=CFG.label_cols, \n                 transform=get_transforms(), img_dir=CFG.train_path, img_ext=CFG.img_ext):\n        \n        super ().__init__()\n        self.df               = df.reset_index (drop=True)\n        self.img_ext          = CFG.img_ext\n        self.img_dir          = img_dir\n        self.label_cols       = label_cols\n        self.img_file_colname = img_file_colname\n        self.transform        = transform\n        return\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        \n        file_name = self.df[self.img_file_colname][idx].replace (self.img_ext, '') + self.img_ext\n        file_path = f'{self.img_dir}/{file_name}'\n        image     = cv2.imread (file_path)                              #;print (file_path)\n        image     = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image = self.transform (image=image)['image'].float ()\n        else:\n            image = ToTensorV2 ()(image = image)[\"image\"].float ()\n        \n        if len (self.label_cols) > 0:\n            label = torch.tensor (self.df.loc[idx, self.label_cols]).float () # long ()\n            return image, label\n        return image","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNet200D_320(nn.Module):\n    \n    def __init__(self, model_name='resnet200d_320'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, 11)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output\n    \n    def freeze (self):\n        # To freeze the residual layers\n        for param in self.model.parameters ():\n            param.requires_grad = False\n\n        for param in self.fc.parameters ():\n            param.requires_grad = False\n        return","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNet200D (nn.Module):\n    \n    def __init__(self, model_name='resnet200d', out_dim=11, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, out_dim)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output\n    \n    def freeze (self):\n        # To freeze the residual layers\n        for param in self.model.parameters ():\n            param.requires_grad = False\n\n        for param in self.fc.parameters ():\n            param.requires_grad = True\n        return\n    \n    def unfreeze (self):\n        # Unfreeze all layers\n        for param in self.model.parameters ():\n            param.requires_grad = True\n        for param in self.fc.parameters ():\n            param.requires_grad = True\n        return","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_metrics (labels, pred_pr):\n    \n    preds   = pred_pr.argmax (-1)             #;print ('labels.shape=', labels.shape, 'preds.shape=', preds.shape, 'pred_logits.shape=', pred_logits.shape)\n    precision, recall, f1, _ = precision_recall_fscore_support (labels, preds, average='macro')\n    acc     = accuracy_score (labels, preds)\n    mcc     = matthews_corrcoef (labels, preds)   # matthews correlation coefficient\n    auc     = -1\n    try:\n        auc = roc_auc_score (labels, pred_pr[:, 1])\n    except:\n        pass\n    metrics = {\n        'mcc'      : mcc,\n        'accuracy' : acc,\n        'f1'       : f1,\n        'precision': precision,\n        'recall'   : recall,\n        'auc'      : auc\n    }\n    return metrics\n\ndef compute_multilabel_binary_metrics (labels, logits):\n    \n    pred_pr = sigmoid (logits)    \n    metrics = []\n    n_class = labels.shape[1]\n    for i in range (n_class):\n        \n        label  = labels[:, i]\n        prob1  = pred_pr[:, i]\n        prob0  = 1 - prob1\n        pred_p = np.hstack ((prob0.reshape ((-1, 1)), prob1.reshape ((-1, 1))))\n        scores = compute_metrics (label, pred_p)\n        metrics.append (scores)\n        \n    # Now Avg over each classes\n    metrics_df = pd.DataFrame (metrics)  \n    auc = list (metrics_df['auc'].values)\n    auc = np.mean ([a for a in auc if a >= 0])\n    metrics_df.drop (columns=['auc'], inplace=True)\n    metrics_df = metrics_df.mean ()\n    metrics_df['auc'] = auc\n    return metrics_df.to_dict ()","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getFolds ():\n    \n    train_folds_df = pd.read_csv (CFG.train_csv)\n    label = train_folds_df[CFG.label_cols]\n    if len (CFG.label_cols) > 1:\n        label = train_folds_df[CFG.label_cols[0]]\n        \n    skf = StratifiedKFold (n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n    for n, (train_index, val_index) in enumerate (skf.split (train_folds_df, label)):\n        train_folds_df.loc[val_index, 'fold'] = int (n)\n    train_folds_df['fold'] = train_folds_df['fold'].astype (int)\n    # print (train_folds_df.groupby (['fold', label]).size ())\n        \n    return train_folds_df","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid (x):  \n    return np.exp (-np.logaddexp (0, -x))","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FFN (nn.Module):\n    \n    def __init__(self, inSize, outSize, drop_prob=0.2):\n        \n        super(FFN, self).__init__()\n        \n        self.dropout    = nn.Dropout (drop_prob)\n        self.batchnorm0 = nn.BatchNorm1d (inSize)\n        self.dense1     = nn.Linear (inSize, outSize)        \n        return\n\n    def forward (self, X):\n        \n        X = self.dense1 (self.dropout (self.batchnorm0 (X)))\n        return X","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate (validation_dataloader, models, ffn, criterion, device):\n        \n        t0 = time.time ()\n        # Put the model in evaluation mode--the dropout layers behave differently\n        # during evaluation.\n        if ffn is not None:\n            ffn.eval ()\n\n        # Tracking variables \n        total_eval_mcc       = 0\n        total_eval_f1        = 0\n        total_eval_precision = 0\n        total_eval_recall    = 0\n        total_eval_auc       = 0\n        total_eval_accuracy  = 0\n        total_eval_loss      = 0\n        nb_eval_steps        = 0\n\n        # Evaluate data for one epoch\n        for batch in validation_dataloader:\n                \n            preds = []\n            images = batch[0].to (device)                   #;print ('images.shape =', images.shape)\n            for model in models:\n                model.eval ()\n                with torch.no_grad ():\n                    pred = model (images)                   #;print ('pred.shape =', pred.shape)\n                    preds.append (pred)                \n            # aggregating model\n            labels   = batch[1].to (device)\n            features = torch.hstack (preds)                 #;print ('features.shape =', features.shape)\n            if ffn is not None:\n                with torch.no_grad ():\n                    logits   = ffn (features)\n            else:\n                logits = features\n            loss     = criterion (logits, labels)            \n            total_eval_loss += loss.item ()\n            logits   = logits.detach ().cpu ().numpy ()\n            labels   = labels.detach ().cpu ().numpy ()\n            \n            # Calculate the accuracy for this batch of test sentences, and\n            # accumulate it over all batches.\n            metrics               = compute_multilabel_binary_metrics (labels, logits)\n            total_eval_mcc       += metrics['mcc']\n            total_eval_f1        += metrics['f1']\n            total_eval_precision += metrics['precision']\n            total_eval_recall    += metrics['recall']\n            total_eval_auc       += metrics['auc']\n            total_eval_accuracy  += metrics['accuracy']\n        # epoch end\n        \n        # Report the final accuracy for this validation run.\n        avg_val_f1 = total_eval_f1 / len (validation_dataloader)\n        print (\"  F1: {0:.3f}\".format (avg_val_f1))\n        avg_val_mcc = total_eval_mcc / len (validation_dataloader)\n        print (\"  MCC: {0:.3f}\".format (avg_val_mcc))\n        avg_val_precision = total_eval_precision / len (validation_dataloader)\n        print (\"  Precision: {0:.3f}\".format (avg_val_precision))\n        avg_val_recall = total_eval_recall / len (validation_dataloader)\n        print (\"  Recall: {0:.3f}\".format (avg_val_recall))\n        avg_val_auc = total_eval_auc / len (validation_dataloader)\n        print (\"  AUC: {0:.3f}\".format (avg_val_auc))\n        avg_val_accuracy = total_eval_accuracy / len (validation_dataloader)\n        print (\"  Accuracy: {0:.3f}\".format (avg_val_accuracy))\n        # Calculate the average loss over all of the batches.\n        avg_val_loss = total_eval_loss / len (validation_dataloader)\n        \n        # Measure how long the validation run took.        \n        print (\"  Validation Loss: {0:.2f}\".format (avg_val_loss))        \n        return avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_batch_opt (labels, pred_logits, ffn, criterion, optimizer, lr_scheduler):\n    \n    # aggregating model\n    features = torch.hstack (pred_logits)                 #;print ('features.shape =', features.shape)\n    logits   = ffn (features)\n    loss     = criterion (logits, labels)\n    loss.backward ()\n    torch.nn.utils.clip_grad_norm_ (ffn.parameters (), CFG.max_grad_norm)\n    optimizer.step ()\n    lr_scheduler.step ()\n    return\n\ndef inference_train (models, train_dataloader, device, ffn, criterion, optimizer, lr_scheduler, epochs, valid_dataloader):\n    \n    global CFG\n    # eval just 1 model as baseline\n    metrics = evaluate (valid_dataloader, [models[0]], None, criterion, device)    \n    print ('model[0] eval metrics:', metrics)\n    max_auc = 0.0\n    for epoch in tqdm (range (epochs)):\n        print ('epoch', epoch)\n        if epoch == 0:\n            for b_i, batch in enumerate (train_dataloader):\n\n                pred_logits = []\n                images = batch[0].to (device)                   #;print ('images.shape =', images.shape)\n                for m_i, model in enumerate (models):\n                    with torch.no_grad ():\n                        pred_logit = model (images)                   #;print ('pred_logit.shape =', pred_logit.shape)\n                    CFG.MODEL_LOGITS[m_i].append (pred_logit)\n                    pred_logits.append (pred_logit)                \n                \n                labels = batch[1]\n                CFG.BATCH_LABELS.append (labels)\n                labels = labels.to (device)\n                one_batch_opt (labels, pred_logits, ffn, criterion, optimizer, lr_scheduler)\n        else:\n            \n            for b_i in range (len (train_dataloader)):\n                \n                pred_logits = []                \n                for m_i, model in enumerate (models):\n                    with torch.no_grad ():\n                        pred_logit = CFG.MODEL_LOGITS[m_i][b_i]          #;print ('pred_logit.shape =', pred_logit.shape)\n                        pred_logits.append (pred_logit)                \n\n                labels = CFG.BATCH_LABELS[b_i].to (device)\n                one_batch_opt (labels, pred_logits, ffn, criterion, optimizer, lr_scheduler)\n            \n        # get metrics\n        avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy = evaluate (valid_dataloader, models, ffn, criterion, device)\n        print ('Epoch -', epoch)\n        # print (avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy)\n        if avg_val_auc > max_auc:\n            print (\"Saving Max-AUC !!\")\n            max_auc = avg_val_auc\n            torch.save (ffn.state_dict (), \"ffn_auc.pth\")\n    return","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fold_loop (fold, train_df=getFolds ()):\n    \n    print (f\"========== fold: {fold} training ==========\")\n    global CFG\n    CFG.MODELS     = []\n    trn_idx        = train_df[train_df['fold'] != fold].index\n    val_idx        = train_df[train_df['fold'] == fold].index\n    train_folds_df = train_df.loc[trn_idx].reset_index (drop=True)\n    valid_folds_df = train_df.loc[val_idx].reset_index (drop=True)\n    train_dataset  = ImgDataset (train_folds_df, transform=get_transforms (), label_cols=CFG.label_cols, img_dir=CFG.train_path)\n    valid_dataset  = ImgDataset (valid_folds_df, transform=get_transforms (), label_cols=CFG.label_cols, img_dir=CFG.train_path)\n    train_dataloader = DataLoader (train_dataset, shuffle=False, batch_size=CFG.batch_size, pin_memory=True, num_workers=4)\n    valid_dataloader = DataLoader (valid_dataset, shuffle=False, batch_size=CFG.batch_size, num_workers=4)\n    class_wt       = 1 / np.array (train_df[CFG.label_cols].sum (axis=0).values)\n    class_wt       = torch.tensor (class_wt / np.sum (class_wt))   ;print ('class_wt =', class_wt)\n    class_wt       = class_wt.to (CFG.device)\n    del train_df; gc.collect ()\n    \n    for path in CFG.MODEL_PATHS:\n        model = ResNet200D ().eval ()\n        model.load_state_dict (torch.load (path, map_location=torch.device ('cpu'))['model'])\n        model.freeze ()\n        CFG.MODELS.append (model.to (CFG.device))\n        CFG.MODEL_LOGITS.append ([])\n    \n    ffn          = FFN ((len (CFG.MODELS))*11, 11, 0.2)\n    # ffn.load_state_dict (torch.load (CFG.ffn_path, map_location=torch.device ('cpu')))\n    ffn          = ffn.train ().to (CFG.device)\n    criterion    = nn.BCEWithLogitsLoss (pos_weight=class_wt)\n    optimizer    = AdamW (ffn.parameters (), lr=CFG.lr, eps=1e-8)\n    epochs       = CFG.epochsNx\n    lr_scheduler = get_linear_schedule_with_warmup (optimizer, num_warmup_steps=500, num_training_steps=len (train_dataloader)*epochs)\n    inference_train (CFG.MODELS, train_dataloader, CFG.device, ffn, criterion, optimizer, lr_scheduler, epochs, valid_dataloader)\n    torch.save (ffn.state_dict (), 'ffn.pth')\n    return ffn","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fold_loop (0)","execution_count":68,"outputs":[{"output_type":"stream","text":"========== fold: 0 training ==========\nclass_wt = tensor([0.5914, 0.0411, 0.0065, 0.1674, 0.0883, 0.0170, 0.0097, 0.0146, 0.0055,\n        0.0022, 0.0563], dtype=torch.float64)\n","name":"stdout"},{"output_type":"stream","text":"\r  0%|          | 0/1 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"  F1: 0.939\n  MCC: 0.000\n  Precision: 0.955\n  Recall: 0.932\n  AUC: nan\n  Accuracy: 0.955\n  Validation Loss: 0.16\nmodel[0] eval metrics: (0.1638001650571823, 0.9393939393939394, 0.0, nan, 0.9545454545454546, 0.9318181818181818, 0.9545454545454546)\nepoch 0\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 1/1 [00:41<00:00, 41.99s/it]","name":"stderr"},{"output_type":"stream","text":"  F1: 0.455\n  MCC: 0.000\n  Precision: 0.455\n  Recall: 0.455\n  AUC: nan\n  Accuracy: 0.455\n  Validation Loss: 1.85\nEpoch - 0\n1.8471516370773315 0.45454545454545453 0.0 nan 0.45454545454545453 0.45454545454545453 0.45454545454545453\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"execute_result","execution_count":68,"data":{"text/plain":"FFN(\n  (dropout): Dropout(p=0.2, inplace=False)\n  (batchnorm0): BatchNorm1d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dense1): Linear(in_features=44, out_features=11, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference (models, ffn, test_loader, device):\n    \n    tk0 = tqdm (enumerate (test_loader), total=len (test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to (device)\n        all_preds_1 = []\n        all_preds_2 = []\n        for model in models:\n            with torch.no_grad ():\n                y_preds1 = model (images)\n                y_preds2 = model (images.flip (-1))            \n            all_preds_1.append (y_preds1)\n            all_preds_2.append (y_preds2)\n            \n        all_preds_1 = torch.hstack (all_preds_1)\n        all_preds_2 = torch.hstack (all_preds_2)\n        all_preds_1 = torch.sigmoid (ffn (all_preds_1))\n        all_preds_2 = torch.sigmoid (ffn (all_preds_2))\n        all_preds   = ((all_preds_1 + all_preds_2) / 2).detach().cpu ().numpy ()\n        probs.append (all_preds)\n    probs = np.concatenate (probs)\n    return probs","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pred ():\n    \n    global CFG    \n    CFG.MODELS = []\n    for path in CFG.MODEL_PATHS:\n            model = ResNet200D ().eval ()\n            model.load_state_dict (torch.load (path, map_location=torch.device ('cpu'))['model'])\n            model.freeze ()\n            CFG.MODELS.append (model.to (CFG.device))\n\n    ffn = FFN ((len (CFG.MODELS))*11, 11, 0.2)\n    ffn.load_state_dict (torch.load (CFG.ffn_path, map_location=torch.device ('cpu')))\n    ffn = ffn.eval ().to (CFG.device)\n    torch.save (ffn.state_dict (), \"ffn_end.pth\")\n\n    test_dataset = ImgDataset (test_df, transform=get_transforms (), label_cols=[], img_dir=CFG.test_path)\n    test_loader  = DataLoader (test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4 , pin_memory=True)\n    predictions  = inference (CFG.MODELS, ffn, test_loader, CFG.device)\n    return predictions","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target_cols = test_df.iloc[:, 1:12].columns.tolist ()\n# predictions = get_pred ()\n# test_df[target_cols] = predictions\n# test_df[['StudyInstanceUID'] + target_cols].to_csv ('submission.csv', index=False)\n# test_df.head ()","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}