{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:23:59.688234Z",
     "iopub.status.busy": "2021-03-10T03:23:59.687644Z",
     "iopub.status.idle": "2021-03-10T03:24:00.338421Z",
     "shell.execute_reply": "2021-03-10T03:24:00.337750Z"
    },
    "papermill": {
     "duration": 0.671449,
     "end_time": "2021-03-10T03:24:00.338597",
     "exception": false,
     "start_time": "2021-03-10T03:23:59.667148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/resnet200d-320-640-fold0-colab-enx7/resnet200d_320_640_fold0_colab_eNx7.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/resnet200d-320-640-fold0-colab-enx7/resnet200d_320_640_fold0_colab_eNx7.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:00.375735Z",
     "iopub.status.busy": "2021-03-10T03:24:00.374885Z",
     "iopub.status.idle": "2021-03-10T03:24:01.030372Z",
     "shell.execute_reply": "2021-03-10T03:24:01.029876Z"
    },
    "papermill": {
     "duration": 0.676545,
     "end_time": "2021-03-10T03:24:01.030505",
     "exception": false,
     "start_time": "2021-03-10T03:24:00.353960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/resnet200d-320-640-fold0-colab-enx2/resnet200d_320_fold0_colab_eNx2.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/resnet200d-320-640-fold0-colab-enx2/resnet200d_320_fold0_colab_eNx2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:01.067915Z",
     "iopub.status.busy": "2021-03-10T03:24:01.065163Z",
     "iopub.status.idle": "2021-03-10T03:24:01.710517Z",
     "shell.execute_reply": "2021-03-10T03:24:01.709365Z"
    },
    "papermill": {
     "duration": 0.66464,
     "end_time": "2021-03-10T03:24:01.710704",
     "exception": false,
     "start_time": "2021-03-10T03:24:01.046064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/resnet200d-320-fold0-enx7/resnet200d_320_fold0_eNx7.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/resnet200d-320-fold0-enx7/resnet200d_320_fold0_eNx7.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:01.752542Z",
     "iopub.status.busy": "2021-03-10T03:24:01.751837Z",
     "iopub.status.idle": "2021-03-10T03:24:02.393514Z",
     "shell.execute_reply": "2021-03-10T03:24:02.392701Z"
    },
    "papermill": {
     "duration": 0.66081,
     "end_time": "2021-03-10T03:24:02.393663",
     "exception": false,
     "start_time": "2021-03-10T03:24:01.732853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/resnet200d320fold0-end/resnet200d_320_fold0_end.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/resnet200d320fold0-end/resnet200d_320_fold0_end.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:02.436609Z",
     "iopub.status.busy": "2021-03-10T03:24:02.435978Z",
     "iopub.status.idle": "2021-03-10T03:24:13.678258Z",
     "shell.execute_reply": "2021-03-10T03:24:13.677717Z"
    },
    "papermill": {
     "duration": 11.268294,
     "end_time": "2021-03-10T03:24:13.678397",
     "exception": false,
     "start_time": "2021-03-10T03:24:02.410103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../input/pytorch-images-seresnet')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from   torch.nn import CrossEntropyLoss, MSELoss\n",
    "from   torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "from   torch.nn import Parameter\n",
    "from   torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from   transformers import TrainingArguments, Trainer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from   fastai.losses import LabelSmoothingCrossEntropy\n",
    "\n",
    "# from   warmup_scheduler import GradualWarmupScheduler\n",
    "from   sklearn import preprocessing\n",
    "from   sklearn.metrics import accuracy_score\n",
    "from   sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from   sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef, roc_auc_score\n",
    "from   sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from   albumentations.pytorch import ToTensorV2\n",
    "from   albumentations.core.transforms_interface import DualTransform\n",
    "from   albumentations.augmentations import functional as AF\n",
    "import cv2\n",
    "\n",
    "from   tqdm import tqdm\n",
    "from   pprint import pprint\n",
    "from   functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from   numba import cuda\n",
    "import warnings\n",
    "warnings.filterwarnings (\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:13.720308Z",
     "iopub.status.busy": "2021-03-10T03:24:13.719726Z",
     "iopub.status.idle": "2021-03-10T03:24:13.723577Z",
     "shell.execute_reply": "2021-03-10T03:24:13.723073Z"
    },
    "papermill": {
     "duration": 0.029734,
     "end_time": "2021-03-10T03:24:13.723698",
     "exception": false,
     "start_time": "2021-03-10T03:24:13.693964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:    \n",
    "    IMAGE_SIZE = 640\n",
    "    TEST_PATH = '../input/ranzcr-clip-catheter-line-classification/test'\n",
    "    device       = torch.device ('cuda' if torch.cuda.is_available () else 'cpu')\n",
    "    num_workers  = 4\n",
    "    model_name   = 'resnet200d_320' # ['deit_base_patch16_224', 'vit_base_patch16_384', 'resnext50_32x4d', 'tf_efficientnet_b7_ns']\n",
    "    size         = 640  # [64, 128, 224, 384, 512, 640, 720]\n",
    "    train        = True\n",
    "    freeze       = True     # this is updated during training   \n",
    "    freeze_epo   = 0.5       # float: these many epochs are with frozen model at the beginning\n",
    "    epochs       = 1 \n",
    "    epochsNx     = 40\n",
    "    lr           = 5e-4\n",
    "    criterion    = 'BCEWithLogitsLoss'    # ['CrossEntropyLoss', 'BCEWithLogitsLoss', 'SmoothBCEwithLogits']\n",
    "    batch_size   = 95 #[10, 32, 64]\n",
    "    weight_decay = 1e-6\n",
    "    max_grad_norm= 1000.0\n",
    "    seed         = 42\n",
    "    target_size  = -1    # init below\n",
    "    n_fold       = 50\n",
    "    train_fold   = [0] #, 1, 2, 3, 4]\n",
    "    print_every  = 100\n",
    "    img_ext      = '.jpg'\n",
    "    img_col      = \"StudyInstanceUID\"\n",
    "    label_cols   = [\n",
    "                    'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n",
    "                    'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n",
    "                    'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n",
    "                    'Swan Ganz Catheter Present'\n",
    "    ]\n",
    "    train_path   = '../input/ranzcr-clip-catheter-line-classification/train'\n",
    "    train_csv    = '../input/ranzcr-clip-catheter-line-classification/train.csv'\n",
    "    test_path    = '../input/ranzcr-clip-catheter-line-classification/test'\n",
    "    test_csv     = '../input/ranzcr-clip-catheter-line-classification/sample_submission.csv'    \n",
    "    \n",
    "    MODEL_PATHS  = [\n",
    "        '../input/resnet200d-320-640-fold0-colab-enx7/resnet200d_320_640_fold0_colab_eNx7.pth',\n",
    "        '../input/resnet200d-320-640-fold0-colab-enx2/resnet200d_320_fold0_colab_eNx2.pth',\n",
    "        '../input/resnet200d-320-fold0-enx7/resnet200d_320_fold0_eNx7.pth',\n",
    "        '../input/resnet200d320fold0-end/resnet200d_320_fold0_end.pth',\n",
    "    ]\n",
    "    MODELS       = []\n",
    "    MODEL_LOGITS = []\n",
    "    LABEL_BATCHES= []\n",
    "    w_path       = \"../input/opt-weighted-pred/W.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:13.761095Z",
     "iopub.status.busy": "2021-03-10T03:24:13.759681Z",
     "iopub.status.idle": "2021-03-10T03:24:13.762038Z",
     "shell.execute_reply": "2021-03-10T03:24:13.762490Z"
    },
    "papermill": {
     "duration": 0.023375,
     "end_time": "2021-03-10T03:24:13.762618",
     "exception": false,
     "start_time": "2021-03-10T03:24:13.739243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything (seed):\n",
    "    \n",
    "    random.seed (seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed (seed)\n",
    "    torch.manual_seed (seed)\n",
    "    torch.cuda.manual_seed (seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    return\n",
    "\n",
    "seed_everything (CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:13.799496Z",
     "iopub.status.busy": "2021-03-10T03:24:13.798996Z",
     "iopub.status.idle": "2021-03-10T03:24:13.818189Z",
     "shell.execute_reply": "2021-03-10T03:24:13.817475Z"
    },
    "papermill": {
     "duration": 0.040762,
     "end_time": "2021-03-10T03:24:13.818315",
     "exception": false,
     "start_time": "2021-03-10T03:24:13.777553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv (CFG.test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:13.853662Z",
     "iopub.status.busy": "2021-03-10T03:24:13.853174Z",
     "iopub.status.idle": "2021-03-10T03:24:13.856704Z",
     "shell.execute_reply": "2021-03-10T03:24:13.856260Z"
    },
    "papermill": {
     "duration": 0.022736,
     "end_time": "2021-03-10T03:24:13.856849",
     "exception": false,
     "start_time": "2021-03-10T03:24:13.834113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms ():\n",
    "        return A.Compose ([\n",
    "            A.Resize (CFG.size, CFG.size),\n",
    "            A.Normalize (),\n",
    "            ToTensorV2 (),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:13.898789Z",
     "iopub.status.busy": "2021-03-10T03:24:13.897461Z",
     "iopub.status.idle": "2021-03-10T03:24:13.900337Z",
     "shell.execute_reply": "2021-03-10T03:24:13.899901Z"
    },
    "papermill": {
     "duration": 0.028263,
     "end_time": "2021-03-10T03:24:13.900442",
     "exception": false,
     "start_time": "2021-03-10T03:24:13.872179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImgDataset (Dataset):\n",
    "    \n",
    "    def __init__(self, df, img_file_colname=CFG.img_col, label_cols=CFG.label_cols, \n",
    "                 transform=get_transforms(), img_dir=CFG.train_path, img_ext=CFG.img_ext):\n",
    "        \n",
    "        super ().__init__()\n",
    "        self.df               = df.reset_index (drop=True)\n",
    "        self.img_ext          = CFG.img_ext\n",
    "        self.img_dir          = img_dir\n",
    "        self.label_cols       = label_cols\n",
    "        self.img_file_colname = img_file_colname\n",
    "        self.transform        = transform\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        file_name = self.df[self.img_file_colname][idx].replace (self.img_ext, '') + self.img_ext\n",
    "        file_path = f'{self.img_dir}/{file_name}'\n",
    "        image     = cv2.imread (file_path)                          \n",
    "        image     = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform (image=image)['image'].float ()\n",
    "        else:\n",
    "            image = ToTensorV2 ()(image = image)[\"image\"].float ()\n",
    "        \n",
    "        if len (self.label_cols) > 0:\n",
    "            label = torch.tensor (self.df.loc[idx, self.label_cols]).float () # long ()\n",
    "            return image, label\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:13.939499Z",
     "iopub.status.busy": "2021-03-10T03:24:13.938832Z",
     "iopub.status.idle": "2021-03-10T03:24:13.942376Z",
     "shell.execute_reply": "2021-03-10T03:24:13.941954Z"
    },
    "papermill": {
     "duration": 0.026531,
     "end_time": "2021-03-10T03:24:13.942484",
     "exception": false,
     "start_time": "2021-03-10T03:24:13.915953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet200D_320 (nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name='resnet200d_320'):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=False)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return output\n",
    "    \n",
    "    def freeze (self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.model.parameters ():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.fc.parameters ():\n",
    "            param.requires_grad = False\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:13.983435Z",
     "iopub.status.busy": "2021-03-10T03:24:13.982100Z",
     "iopub.status.idle": "2021-03-10T03:24:13.984579Z",
     "shell.execute_reply": "2021-03-10T03:24:13.984980Z"
    },
    "papermill": {
     "duration": 0.027057,
     "end_time": "2021-03-10T03:24:13.985110",
     "exception": false,
     "start_time": "2021-03-10T03:24:13.958053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet200D (nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name='resnet200d', out_dim=11, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=False)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return output\n",
    "    \n",
    "    def freeze (self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.model.parameters ():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.fc.parameters ():\n",
    "            param.requires_grad = True\n",
    "        return\n",
    "    \n",
    "    def unfreeze (self):\n",
    "        # Unfreeze all layers\n",
    "        for param in self.model.parameters ():\n",
    "            param.requires_grad = True\n",
    "        for param in self.fc.parameters ():\n",
    "            param.requires_grad = True\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.026391Z",
     "iopub.status.busy": "2021-03-10T03:24:14.025741Z",
     "iopub.status.idle": "2021-03-10T03:24:14.029240Z",
     "shell.execute_reply": "2021-03-10T03:24:14.028826Z"
    },
    "papermill": {
     "duration": 0.028807,
     "end_time": "2021-03-10T03:24:14.029344",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.000537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics (labels, pred_pr):\n",
    "    \n",
    "    preds   = pred_pr.argmax (-1)             #;print ('labels.shape=', labels.shape, 'preds.shape=', preds.shape, 'pred_logits.shape=', pred_logits.shape)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support (labels, preds, average='macro')\n",
    "    acc     = accuracy_score (labels, preds)\n",
    "    mcc     = matthews_corrcoef (labels, preds)   # matthews correlation coefficient\n",
    "    auc     = -1\n",
    "    try:\n",
    "        auc = roc_auc_score (labels, pred_pr[:, 1])\n",
    "    except:\n",
    "        pass\n",
    "    metrics = {\n",
    "        'mcc'      : mcc,\n",
    "        'accuracy' : acc,\n",
    "        'f1'       : f1,\n",
    "        'precision': precision,\n",
    "        'recall'   : recall,\n",
    "        'auc'      : auc\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def compute_multilabel_binary_metrics (labels, logits):\n",
    "    \n",
    "    pred_pr = sigmoid (logits)    \n",
    "    metrics = []\n",
    "    n_class = labels.shape[1]\n",
    "    for i in range (n_class):\n",
    "        \n",
    "        label  = labels[:, i]\n",
    "        prob1  = pred_pr[:, i]\n",
    "        prob0  = 1 - prob1\n",
    "        pred_p = np.hstack ((prob0.reshape ((-1, 1)), prob1.reshape ((-1, 1))))\n",
    "        scores = compute_metrics (label, pred_p)\n",
    "        metrics.append (scores)\n",
    "        \n",
    "    # Now Avg over each classes\n",
    "    metrics_df = pd.DataFrame (metrics)  \n",
    "    auc = list (metrics_df['auc'].values)\n",
    "    auc = np.mean ([a for a in auc if a >= 0])\n",
    "    metrics_df.drop (columns=['auc'], inplace=True)\n",
    "    metrics_df = metrics_df.mean ()\n",
    "    metrics_df['auc'] = auc\n",
    "    return metrics_df.to_dict ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.066660Z",
     "iopub.status.busy": "2021-03-10T03:24:14.066159Z",
     "iopub.status.idle": "2021-03-10T03:24:14.069750Z",
     "shell.execute_reply": "2021-03-10T03:24:14.069365Z"
    },
    "papermill": {
     "duration": 0.024831,
     "end_time": "2021-03-10T03:24:14.069888",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.045057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getFolds ():\n",
    "    \n",
    "    train_folds_df = pd.read_csv (CFG.train_csv)\n",
    "    label = train_folds_df[CFG.label_cols]\n",
    "    if len (CFG.label_cols) > 1:\n",
    "        label = train_folds_df[CFG.label_cols[0]]\n",
    "        \n",
    "    skf = StratifiedKFold (n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "    for n, (train_index, val_index) in enumerate (skf.split (train_folds_df, label)):\n",
    "        train_folds_df.loc[val_index, 'fold'] = int (n)\n",
    "    train_folds_df['fold'] = train_folds_df['fold'].astype (int)\n",
    "    # print (train_folds_df.groupby (['fold', label]).size ())\n",
    "        \n",
    "    return train_folds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.106376Z",
     "iopub.status.busy": "2021-03-10T03:24:14.105837Z",
     "iopub.status.idle": "2021-03-10T03:24:14.109533Z",
     "shell.execute_reply": "2021-03-10T03:24:14.109086Z"
    },
    "papermill": {
     "duration": 0.023616,
     "end_time": "2021-03-10T03:24:14.109649",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.086033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid (x):  \n",
    "    return np.exp (-np.logaddexp (0, -x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.154630Z",
     "iopub.status.busy": "2021-03-10T03:24:14.153891Z",
     "iopub.status.idle": "2021-03-10T03:24:14.156456Z",
     "shell.execute_reply": "2021-03-10T03:24:14.156067Z"
    },
    "papermill": {
     "duration": 0.030737,
     "end_time": "2021-03-10T03:24:14.156564",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.125827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate (validation_dataloader, models, W, criterion, device):\n",
    "        \n",
    "        t0 = time.time ()\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_mcc       = 0\n",
    "        total_eval_f1        = 0\n",
    "        total_eval_precision = 0\n",
    "        total_eval_recall    = 0\n",
    "        total_eval_auc       = 0\n",
    "        total_eval_accuracy  = 0\n",
    "        total_eval_loss      = 0\n",
    "        nb_eval_steps        = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "                \n",
    "            preds = []\n",
    "            images = batch[0].to (device)                   #;print ('images.shape =', images.shape)\n",
    "            for model in models:\n",
    "                model.eval ()\n",
    "                with torch.no_grad ():\n",
    "                    pred = model (images)   # torch.sigmoid (model (images))\n",
    "                    preds.append (pred)          \n",
    "            # aggregating model\n",
    "            labels   = batch[1]     # .to (device)\n",
    "            features = torch.hstack (preds).cpu ()                 #;print ('features.shape =', features.shape)\n",
    "            preds_lg = torch.zeros (labels.size ())\n",
    "            for i in range (len (W)):\n",
    "                preds_lg += W[i] * features[:, i:i+11]\n",
    "            loss     = criterion (preds_lg, labels)            \n",
    "            total_eval_loss += loss.item ()\n",
    "            preds_lg = preds_lg.detach ().cpu ().numpy ()\n",
    "            labels   = labels.detach ().cpu ().numpy ()\n",
    "            \n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            metrics               = compute_multilabel_binary_metrics (labels, preds_lg)\n",
    "            total_eval_mcc       += metrics['mcc']\n",
    "            total_eval_f1        += metrics['f1']\n",
    "            total_eval_precision += metrics['precision']\n",
    "            total_eval_recall    += metrics['recall']\n",
    "            total_eval_auc       += metrics['auc']\n",
    "            total_eval_accuracy  += metrics['accuracy']\n",
    "        # epoch end\n",
    "        \n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_f1 = total_eval_f1 / len (validation_dataloader)\n",
    "        print (\"  F1: {0:.3f}\".format (avg_val_f1))\n",
    "        avg_val_mcc = total_eval_mcc / len (validation_dataloader)\n",
    "        print (\"  MCC: {0:.3f}\".format (avg_val_mcc))\n",
    "        avg_val_precision = total_eval_precision / len (validation_dataloader)\n",
    "        print (\"  Precision: {0:.3f}\".format (avg_val_precision))\n",
    "        avg_val_recall = total_eval_recall / len (validation_dataloader)\n",
    "        print (\"  Recall: {0:.3f}\".format (avg_val_recall))\n",
    "        avg_val_auc = total_eval_auc / len (validation_dataloader)\n",
    "        print (\"  AUC: {0:.3f}\".format (avg_val_auc))\n",
    "        avg_val_accuracy = total_eval_accuracy / len (validation_dataloader)\n",
    "        print (\"  Accuracy: {0:.3f}\".format (avg_val_accuracy))\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len (validation_dataloader)\n",
    "        \n",
    "        # Measure how long the validation run took.        \n",
    "        print (\"  Validation Loss: {0:.2f}\".format (avg_val_loss))        \n",
    "        return avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.202407Z",
     "iopub.status.busy": "2021-03-10T03:24:14.201718Z",
     "iopub.status.idle": "2021-03-10T03:24:14.204508Z",
     "shell.execute_reply": "2021-03-10T03:24:14.204117Z"
    },
    "papermill": {
     "duration": 0.032125,
     "end_time": "2021-03-10T03:24:14.204626",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.172501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_batch_opt (labels, preds, step, total_steps, W, criterion):\n",
    "    \n",
    "    # aggregating model\n",
    "    features = torch.hstack (preds).cpu ()                   #;print ('features.shape =', features.shape)\n",
    "    preds    = torch.zeros ((labels.size(0), labels.size(1)))\n",
    "    for i in range (len (W)):        \n",
    "        preds += W[i] * features[:, i:i+11]\n",
    "    loss = criterion (preds, labels)                         #;print (\"loss =\", loss)\n",
    "    loss.backward ()                                         #;print (\"W.grad =\", W.grad)\n",
    "    torch.nn.utils.clip_grad_norm_ (W, CFG.max_grad_norm)\n",
    "    lr = CFG.lr * (total_steps - step) / total_steps\n",
    "    with torch.no_grad ():        \n",
    "        W -= lr * W.grad\n",
    "        W.grad = None\n",
    "        # W= W / torch.linalg.norm (W, 1)\n",
    "    return\n",
    "\n",
    "def inference_train (models, train_dataloader, device, W, criterion, epochs, valid_dataloader, isOnlyValid=False):\n",
    "    \n",
    "    global CFG\n",
    "    if isOnlyValid:\n",
    "        metrics = evaluate (valid_dataloader, [models[0]], [1], criterion, device)\n",
    "        print ('1st model metrics :', metrics)\n",
    "        \n",
    "    step = 0\n",
    "    max_auc = 0.0\n",
    "    total_steps = len (train_dataloader) * epochs\n",
    "    for epoch in tqdm (range (epochs)):\n",
    "        print ('epoch', epoch)\n",
    "        if epoch == 0:\n",
    "            for bi, batch in enumerate (train_dataloader):\n",
    "\n",
    "                preds = []\n",
    "                images = batch[0].to (device)                   #;print ('images.shape =', images.shape)\n",
    "                for mi, model in enumerate (models):\n",
    "                    with torch.no_grad ():\n",
    "                        pred = model (images)               #torch.sigmoid (model (images))   \n",
    "                    CFG.MODEL_LOGITS[mi].append (pred)                    \n",
    "                    preds.append (pred) \n",
    "                \n",
    "                labels = batch[1]  #.to (device)\n",
    "                CFG.LABEL_BATCHES.append (labels)\n",
    "                one_batch_opt (labels, preds, step, total_steps, W, criterion)\n",
    "                step  += 1\n",
    "        else:\n",
    "            for bi in range (len (train_dataloader)):\n",
    "                \n",
    "                preds = []                \n",
    "                for mi, model in enumerate (models):\n",
    "                    pred = CFG.MODEL_LOGITS[mi][bi]\n",
    "                    preds.append (pred) \n",
    "                labels = CFG.LABEL_BATCHES[bi]\n",
    "                one_batch_opt (labels, preds, step, total_steps, W, criterion)\n",
    "                step  += 1\n",
    "        \n",
    "        avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy = evaluate (valid_dataloader, models, W, criterion, device)\n",
    "        if avg_val_auc > max_auc:\n",
    "            max_auc = avg_val_auc\n",
    "            print (\"Saving Max-AUC W =\", W)\n",
    "            torch.save (W, 'W_auc.pt')            \n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.248570Z",
     "iopub.status.busy": "2021-03-10T03:24:14.248040Z",
     "iopub.status.idle": "2021-03-10T03:24:14.370740Z",
     "shell.execute_reply": "2021-03-10T03:24:14.370213Z"
    },
    "papermill": {
     "duration": 0.150163,
     "end_time": "2021-03-10T03:24:14.370884",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.220721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fold_loop (fold, train_df=getFolds (), isOnlyValid=False):\n",
    "    \n",
    "    print (f\"========== fold: {fold} training ==========\")\n",
    "    global CFG\n",
    "    CFG.MODELS     = []\n",
    "    trn_idx        = train_df[train_df['fold'] != fold].index\n",
    "    val_idx        = train_df[train_df['fold'] == fold].index\n",
    "    train_folds_df = train_df.loc[trn_idx].reset_index (drop=True)\n",
    "    valid_folds_df = train_df.loc[val_idx].reset_index (drop=True)\n",
    "    train_dataset  = ImgDataset (train_folds_df, transform=get_transforms (), label_cols=CFG.label_cols, img_dir=CFG.train_path)\n",
    "    valid_dataset  = ImgDataset (valid_folds_df, transform=get_transforms (), label_cols=CFG.label_cols, img_dir=CFG.train_path)\n",
    "    train_dataloader = DataLoader (train_dataset, shuffle=False, batch_size=CFG.batch_size, pin_memory=True, num_workers=4)\n",
    "    valid_dataloader = DataLoader (valid_dataset, shuffle=False, batch_size=CFG.batch_size, num_workers=4)\n",
    "    class_wt       = 1 / np.array (train_df[CFG.label_cols].sum (axis=0).values)\n",
    "    class_wt       = torch.tensor (class_wt / np.sum (class_wt))   ;print ('class_wt =', class_wt)\n",
    "    # class_wt       = class_wt.to (CFG.device)\n",
    "    del train_df; gc.collect ()\n",
    "    \n",
    "    for path in CFG.MODEL_PATHS:\n",
    "        model = ResNet200D ().eval ()\n",
    "        model.load_state_dict (torch.load (path, map_location=torch.device ('cpu'))['model'])\n",
    "        model.freeze ()\n",
    "        CFG.MODELS.append (model.to (CFG.device))\n",
    "        CFG.MODEL_LOGITS.append ([])\n",
    "    \n",
    "    W            = torch.tensor ([0.65, 0.30, 0.12, 0.20], requires_grad=True).float () #.to (CFG.device)\n",
    "    criterion    = nn.BCEWithLogitsLoss (pos_weight=class_wt)\n",
    "    epochs       = CFG.epochsNx    \n",
    "    inference_train (CFG.MODELS, train_dataloader, CFG.device, W, criterion, epochs, valid_dataloader, isOnlyValid)\n",
    "    # W          = W / torch.linalg.norm (W, 1)\n",
    "    torch.save (W, 'W_end.pt')\n",
    "    print ('ending W =', W)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.408164Z",
     "iopub.status.busy": "2021-03-10T03:24:14.407601Z",
     "iopub.status.idle": "2021-03-10T03:24:14.411638Z",
     "shell.execute_reply": "2021-03-10T03:24:14.411211Z"
    },
    "papermill": {
     "duration": 0.024214,
     "end_time": "2021-03-10T03:24:14.411747",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.387533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_fold_loop (0, isOnlyValid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.016472,
     "end_time": "2021-03-10T03:24:14.444877",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.428405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0165,
     "end_time": "2021-03-10T03:24:14.477898",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.461398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.520638Z",
     "iopub.status.busy": "2021-03-10T03:24:14.519952Z",
     "iopub.status.idle": "2021-03-10T03:24:14.522914Z",
     "shell.execute_reply": "2021-03-10T03:24:14.522470Z"
    },
    "papermill": {
     "duration": 0.028584,
     "end_time": "2021-03-10T03:24:14.523022",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.494438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference (models, W, test_loader, device):\n",
    "    \n",
    "    tk0 = tqdm (enumerate (test_loader), total=len (test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to (device)\n",
    "        all_preds_1 = []\n",
    "        all_preds_2 = []\n",
    "        for model in models:\n",
    "            with torch.no_grad ():\n",
    "                y_preds1 = model (images)            # torch.sigmoid (model (images))\n",
    "                y_preds2 = model (images.flip (-1))  # torch.sigmoid (model (images.flip (-1)))\n",
    "            all_preds_1.append (y_preds1)\n",
    "            all_preds_2.append (y_preds2)\n",
    "            \n",
    "        all_preds_1 = torch.hstack (all_preds_1).cpu ()\n",
    "        all_preds_2 = torch.hstack (all_preds_2).cpu ()\n",
    "        preds_1 = torch.zeros ((images.size (0), 11))        #;print ('preds_1.shape =', preds_1.shape)\n",
    "        for i in range (len (W)):\n",
    "            preds_1 += W[i] * all_preds_1[:, i:i+11]\n",
    "        # print ('preds_1.shape =', preds_1.shape)\n",
    "        preds_2 = torch.zeros ((images.size (0), 11))\n",
    "        for i in range (len (W)):\n",
    "            preds_2 += W[i] * all_preds_2[:, i:i+11]\n",
    "        \n",
    "        all_preds   = ((torch.sigmoid (preds_1) + torch.sigmoid (preds_2)) / 2).detach().numpy ()\n",
    "        probs.append (all_preds)\n",
    "    probs = np.concatenate (probs)                           ;print ('probs.shape =', probs.shape)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.562981Z",
     "iopub.status.busy": "2021-03-10T03:24:14.562244Z",
     "iopub.status.idle": "2021-03-10T03:24:14.565156Z",
     "shell.execute_reply": "2021-03-10T03:24:14.564697Z"
    },
    "papermill": {
     "duration": 0.025879,
     "end_time": "2021-03-10T03:24:14.565275",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.539396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pred ():\n",
    "    \n",
    "    global CFG    \n",
    "    CFG.MODELS = []\n",
    "    for path in CFG.MODEL_PATHS:\n",
    "            model = ResNet200D_320 ().eval ()\n",
    "            model.load_state_dict (torch.load (path, map_location=torch.device ('cpu'))['model'])\n",
    "            model.freeze ()\n",
    "            CFG.MODELS.append (model.to (CFG.device))\n",
    "\n",
    "    W = torch.tensor ([0.6538, 0.1577, 0.1753, 0.2345]).float ()\n",
    "    # W = torch.load (CFG.w_path, map_location=torch.device ('cpu')).float ()     ;print (W)\n",
    "    # torch.save (W, \"W.pth\")\n",
    "    \n",
    "    test_dataset = ImgDataset (test_df, transform=get_transforms (), label_cols=[], img_dir=CFG.test_path)\n",
    "    test_loader  = DataLoader (test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4 , pin_memory=True)\n",
    "    predictions  = inference (CFG.MODELS, W, test_loader, CFG.device)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:24:14.605058Z",
     "iopub.status.busy": "2021-03-10T03:24:14.604465Z",
     "iopub.status.idle": "2021-03-10T03:41:58.271121Z",
     "shell.execute_reply": "2021-03-10T03:41:58.270148Z"
    },
    "papermill": {
     "duration": 1063.68901,
     "end_time": "2021-03-10T03:41:58.271260",
     "exception": false,
     "start_time": "2021-03-10T03:24:14.582250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [17:07<00:00, 27.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs.shape = (3582, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>ETT - Abnormal</th>\n",
       "      <th>ETT - Borderline</th>\n",
       "      <th>ETT - Normal</th>\n",
       "      <th>NGT - Abnormal</th>\n",
       "      <th>NGT - Borderline</th>\n",
       "      <th>NGT - Incompletely Imaged</th>\n",
       "      <th>NGT - Normal</th>\n",
       "      <th>CVC - Abnormal</th>\n",
       "      <th>CVC - Borderline</th>\n",
       "      <th>CVC - Normal</th>\n",
       "      <th>Swan Ganz Catheter Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.46923145579096002617106567297135160932</td>\n",
       "      <td>0.066318</td>\n",
       "      <td>0.396227</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.022576</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>0.989580</td>\n",
       "      <td>0.863640</td>\n",
       "      <td>0.793051</td>\n",
       "      <td>0.990422</td>\n",
       "      <td>0.999792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.84006870182611080091824109767561564887</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.504665</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.12219033294413119947515494720687541672</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.031318</td>\n",
       "      <td>0.083497</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.84994474380235968109906845540706092671</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.125644</td>\n",
       "      <td>0.041073</td>\n",
       "      <td>0.940307</td>\n",
       "      <td>0.076578</td>\n",
       "      <td>0.019896</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.277021</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.35798987793805669662572108881745201372</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.207606</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   StudyInstanceUID  \\\n",
       "0  1.2.826.0.1.3680043.8.498.46923145579096002617106567297135160932   \n",
       "1  1.2.826.0.1.3680043.8.498.84006870182611080091824109767561564887   \n",
       "2  1.2.826.0.1.3680043.8.498.12219033294413119947515494720687541672   \n",
       "3  1.2.826.0.1.3680043.8.498.84994474380235968109906845540706092671   \n",
       "4  1.2.826.0.1.3680043.8.498.35798987793805669662572108881745201372   \n",
       "\n",
       "   ETT - Abnormal  ETT - Borderline  ETT - Normal  NGT - Abnormal  \\\n",
       "0        0.066318          0.396227      0.024030        0.004859   \n",
       "1        0.000013          0.000037      0.000073        0.000036   \n",
       "2        0.000035          0.000104      0.000061        0.000048   \n",
       "3        0.000393          0.000730      0.022023        0.125644   \n",
       "4        0.000017          0.000053      0.000071        0.000092   \n",
       "\n",
       "   NGT - Borderline  NGT - Incompletely Imaged  NGT - Normal  CVC - Abnormal  \\\n",
       "0          0.022576                   0.034670      0.989580        0.863640   \n",
       "1          0.000093                   0.000062      0.004850        0.004510   \n",
       "2          0.000211                   0.000054      0.002036        0.004996   \n",
       "3          0.041073                   0.940307      0.076578        0.019896   \n",
       "4          0.000153                   0.000094      0.012517        0.005136   \n",
       "\n",
       "   CVC - Borderline  CVC - Normal  Swan Ganz Catheter Present  \n",
       "0          0.793051      0.990422                    0.999792  \n",
       "1          0.001236      0.504665                    0.000007  \n",
       "2          0.031318      0.083497                    0.000027  \n",
       "3          0.011728      0.277021                    0.000277  \n",
       "4          0.002988      0.207606                    0.000009  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = test_df.iloc[:, 1:12].columns.tolist ()\n",
    "predictions = get_pred ()\n",
    "test_df[target_cols] = predictions\n",
    "test_df[['StudyInstanceUID'] + target_cols].to_csv ('submission.csv', index=False)\n",
    "test_df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028799,
     "end_time": "2021-03-10T03:41:58.331084",
     "exception": false,
     "start_time": "2021-03-10T03:41:58.302285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T03:41:58.392613Z",
     "iopub.status.busy": "2021-03-10T03:41:58.391998Z",
     "iopub.status.idle": "2021-03-10T03:41:58.395119Z",
     "shell.execute_reply": "2021-03-10T03:41:58.395693Z"
    },
    "papermill": {
     "duration": 0.036346,
     "end_time": "2021-03-10T03:41:58.395884",
     "exception": false,
     "start_time": "2021-03-10T03:41:58.359538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print ('Done !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1088.049878,
   "end_time": "2021-03-10T03:42:02.650964",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-10T03:23:54.601086",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
